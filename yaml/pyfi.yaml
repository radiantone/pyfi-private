version: '1.0'

# This creates database records and a running scheduler will do the deployments
network:
  name: network-1
  queues:
    pyfi.queue1:
      message_ttl: 200000
      durable: true
      expires: 200
    pyfi.queue2:
      message_ttl: 200000
      expires: 200
      durable: true
    pyfi.queue3:
      message_ttl: 200000
      expires: 200
      durable: true
  nodes:
    agent3:
      clean: true
      enabled: true
      hostname: agent3
      ssh:
        key: '/home/darren/.ssh/id_rsa.pub'
        user: 'darren'
      path: /home/darren/agent3/work
      ini: /home/darren/pyfi.ini
      polar: /home/darren/pyfi.polar
      agents:
        agent1:
          parameters:
            pool: 5
            size: 10
          processors:
            proc3: 
                # These properties allow the code repo for this processor 'gitrepo' to be
                # installed in a container image that already has pyfi inside it
                # The user code then runs safely inside the container without harming the host system 
                container_image: pyfi/processor
                use_container: true
                detached: true

                branch: main
                pyfirepo: 'https://radiantone:xxxx@github.com/radiantone/pyfi-private#egg=pyfi'
                gitrepo: 'https://github.com/radiantone/pyfi-processors#egg=ext-processor'
                commit:
                module: ext.processors.sample
                beat: false
                cpus: 2
                sockets:
                  ext.processors.sample.emit_one:
                    interval: -1
                    queue: 
                      name: pyfi.queue1
                    task:
                      function: 
                        name: emit_one
                  ext.processors.sample.emit_two:
                    queue: 
                      name: pyfi.queue3
                    task:
                      function: 
                        name: emit_two    
      services:
        docker:
          websockets:
            daemon: true
            environment:
              - LISTEN_PROCESSOR=proc1
              - LISTEN_CHANNEL=task
    agent2:
      clean: false
      hostname: agent2
      ini: /home/darren/pyfi.ini
      polar: /home/darren/pyfi.polar
      ssh:
        key: '/home/darren/.ssh/id_rsa.pub'
        user: 'darren'
      path: /home/darren/agent2/work
      agents:
        agent1:
          parameters:
            pool: 5
            size: 10
          processors:
            proc4: 
              branch: main
              pyfirepo: 'https://radiantone:xxxx@github.com/radiantone/pyfi-private#egg=pyfi'
              gitrepo: 'https://github.com/radiantone/pyfi-processors#egg=ext-processor'
              commit:
              module: ext.processors.sample
              beat: false
              cpus: 1
              sockets:
                ext.processors.sample.add_two:
                  queue: 
                    name: pyfi.queue2
                  task:
                    function: 
                      name: add_two
                      arguments: true
                      resetonexecute: true

  deployments:
    #proc3.d1:
    #  hostname: phoenix
    #  cpus: 3
    #  processor: proc3
    proc3.d2:
      hostname: agent2
      cpus: 3
      processor: proc3      
    proc4.d1:
      hostname: agent3
      cpus: 3
      processor: proc4

  plugs:
    plug1:
      source: ext.processors.sample.emit_one
      target: ext.processors.sample.add_two
      argument: one
      queue:
        name: pyfi.queue4
    plug2:
      source: ext.processors.sample.emit_two
      target: ext.processors.sample.add_two
      argument: two
      queue:
        name: pyfi.queue5
# This will create work records which the scheduler will deploy
work:
  
# This will create scheduled tasks (i.e. jobs)
jobs:

# This will create immediate executions using the API models
executions: