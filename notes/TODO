- Implement pretty table for ls command


DESIGN
------
1. Re-write worker/task dispatching to use signals DONE

- Use task signals instead of harness so Flower will reflect actual task info (instead of harness) DONE
- task_prerun signal will query database for connected plugs and then populate the tasks kwargs with the IO objects it needs DONE
- task_postrun will inspect the tasks kwargs IO object for results and then invoke the downstream processor tasks with those results DONE
This way, all the task reporting reflects the actual tasks

TESTS
-----

1. Verified multi server, multi processor, multi agent realtime, reliable messaging across processors that all pull from git
    a. All messages get delivered DONE
    b. Message queues are consumed in timely manner DONE
    c. No exceptions DONE

SMALL TASKS
--------------
- Port to sqlalchemy and alembic DONE
- Steps to migrate database DONE
- Update object commands 80%
- Move processor from one host to another (db only) 100%
    - Show agents responding on each end to datbase 50%
- Processor lifecycle logging
- Processor code logging, events?
- Processor error handling
- Processor Security
- Processor restart and update when git repo changes?
- Internal thread to refresh outlet queue processors so its not hitting database every invoke
- Additional processor configs e.g. rate_limit, TTL, etc
- Invocation/Message expiries
- Abandoned queues get deleted automatically
- Agent refreshes processor if lastupdated time changes
    - Processor config determines if/when/how often a processor can be updated
- Organize repo directories DONE
- Add alembic config DONE
- Edit migrations/env.py with target_metadata DONE
- pyfi db init calls alembic init and fixes env.py?


UPCOMING
--------

1. Agent clones gitrepo for processor DONE
2. Agent loads module from local repo, executes tasks within it across celery DONE
3. Agent defines queues in its worker app based on queues in database, including type (direct, topic, etc)
4. Adding outlets and plugs to processors DONE
5. Specifying module for processor DONE
6. Specifying function within processor module for a schedule DONE
7. Execute processor function with beat schedule from harness DONE
8. Processor subscribes to outlet queues on startup DONE
9. Client executes processor function across its outlet queues DONE


PYFI TODOs
-------------

1. For delete dialogs, mention the thing being deleted by name and type
2. Restrict plugs from attaching to self node
3. Restrict input plugs from attaching to output plugs. Also same type plugs. DONE
4. Complete all popup menu designs
5. Complete all floating dialogs for nodes
      Read/Write
      Config
      Code
      
6. Complete all drag and drop node types and templates
    Processor
    Port In
    Port Out
    Process Group
    Remote Process Group
    Funnel
    Router
    Template
    Label
7. Application wide dialogs & wizards
8. Code cleanup, remove old references. DONE
9. Backend service objects (e.g. ObjectService etc)
10. Security plugin (e.g. OAuth), or use Okta
11. SQLAlchemy data model (e.g. Flow, Processor, Settings, User, Node, Task, Log, Queue, etc) 10%
     This data model is managed by PYFI micro-service, UI and also task callbacks that need to store metadata about the task completion.
     The UI will read from this database to display info
     The CLI will also read from this database
     Celery can use this as a backend as well, allowing for joins across PYFI data tables and celery result tables.
12. Click select processor DONE
13. Click a processor and it rises to front and triggers selection event DONE
14. Processor selection event enables operation buttons gui DONE
15. Create queue objects and specify type of queue and qualities like durable, etc  
      When adding plugs to outlets, you select the existing queue that connection is to use or create a new one on-the-fly with wizard dialog


CLI TODO
--------

1. Factor out database and celery configs (passed in on cli) DONE
2. Agent server and process. database update DONE
3. Run postgres container for sqlaclchemy DONE
4. Use postgresdb for cli persistence (not sqllite) DONE
5. 

Agent TODO
----------

1. Agent can manage local git repos for processor code.
2. Agent monitors database and will affect local git repo to the commit version specified by the user and restart workers
3. Agent uses a file lock to synchronize with workers so it can do things in between worker tasks without race conditions
4. Agent monitors database for processors, spawns workers to match. DONE
5. Create queues before launching worker based on queues attached to processor.


