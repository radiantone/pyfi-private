
Phase 1 Goals
-------------

- General UI design, initial implementation and flow DONE
- pyfi cli design DONE
- pyfi agent that monitors remote db and updates worker processes DONE
- pyfi api that executes tasks over pyfi cli workers controlled by pyfi cli agent only DONE (concept)
- execute dynamic code task over pyfi agent/worker network DONE(concept)
- pyfi cli database admin DONE(concept)
- pyfi database models DONE
- pyfi architecture slides DONE
- pyfi architecture containers (running)
- pyfi-ui repo DONE
- Data model design DONE


Phase 2 Goals
-------------

- Create/Manage pyfi network across machines DONE
- Remote deploy/manage of pyfi agents using paramiko ssh
- Remote syncing of venv's with pyfi
- Remotely execute tasks and dynamic code DONE
- pyfi cli network/queue/cluster/agent status DONE
- use postgres container for sqlalchemy DONE
- Detailed data model DONE
- data model/table migration DONE
- Use Cases:
    - Agents spawn workers for processors across machines  DONE
    - pyfi cli creates, starts, stops, restarts processors DONE
    - Agents resume workers after restart unless processor is in stopped model DONE
    - User modules are retrieved from git DONE
- --gitrepo, --commit and --dir options for agents to locate git repo and where to store it. Agent
then updates its local repo based on the desired commit level for the code before running the worker
so the proper code is in place. DONE
- Throughput TESTS DONE
- Fix memory issues DONE

Phase 3 Goals
-------------

- Monitor tasks using flower and rabbitmq admin. See individual task info. DONE
- Expand processor/task configs e.g. retries, etc.  DONE
- Implement logging inside task signal functions DONE
- Use flower API to get metadata?
- Stop a processor after restarting it 5 times in 5 minutes
- Test/Observe rate limiting
- Test/Observe worker scaling (via flower) and worker auto-scaling
- Initial PYFI API for UI
- Add pyfi API to compose file
- Add nginx to compose file to front PYFI API and Flower API into one API Route 65%
- Create nginx volume with app static build in it or mounted as volume DONE
- Run agent in supervisor, test fault tolerance and message reliability DONE

- Flow objects and data model
   - Link to all processors
   - Stopping or starting a flow invokes same method on processors

- Password protect processors: lock & unlock. Login dialogs

- Obtain queue message status from Flower for a particular queue or task 

- Add user CLI commands DONE
- Delete CLI commands DONE


Phase 4 Goals
-------------

- Build flows with CLI or client API DONE
- Invocations complete regardless of when processors come online DONE
    - Flows complete even if partially available DONE
- Queues are reclaimed after expiry when no consumers attached DONE
- APScheduler 90%
- ls calls, ls call->shows result DONE
    - Add result size to CallModel
- Port pubsub to redis DONE
- CPU affinity for worker processors, scheduler decides
- cli listen works with redis now DONE
- User RLS row level security in database DONE
- Scheduler CLI commands 80%
- Scheduler task
    - Monitors nodes associated with scheduler
    - If a processor has no worker, find a node and hostname to the processor. Agent will take over then
- ls node tree printer DONE
- More complete relational model 95%
- isolated virtualenvs for processors using github w/logins DONE
- Proper room joining DONE
- Proper queue subscriptions in worker DONE
- tasks can send output to 'log','task','data' channels
- Move processor between hosts while running DONE
- Client API 80%

